{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "컴퓨터 비전 학습 대회 최종본.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "9hrU0APXaje1",
        "outputId": "33c97e19-447f-4182-9bef-35ea70433969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "from google.colab import drive # 마운팅\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "WRwccOqQajfD"
      },
      "source": [
        "import time\n",
        "import random\n",
        "import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "# LOAD LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# How to check if Keras is using GPU?\n",
        "\n",
        "\n",
        "train = pd.read_csv('./My Drive/train.csv')\n",
        "test  = pd.read_csv('./My Drive/test.csv')\n",
        "submission = pd.read_csv('./My Drive/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXuhyUDMa4ER",
        "outputId": "2007e321-7e09-4107-ed6b-60a6ebea5b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>digit</th>\n",
              "      <th>letter</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2043</th>\n",
              "      <td>2044</td>\n",
              "      <td>6</td>\n",
              "      <td>V</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2044</th>\n",
              "      <td>2045</td>\n",
              "      <td>1</td>\n",
              "      <td>L</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2045</th>\n",
              "      <td>2046</td>\n",
              "      <td>9</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2046</th>\n",
              "      <td>2047</td>\n",
              "      <td>0</td>\n",
              "      <td>Z</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2047</th>\n",
              "      <td>2048</td>\n",
              "      <td>5</td>\n",
              "      <td>Z</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2048 rows × 787 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  digit letter  0  1  2  3  4  ...  776  777  778  779  780  781  782  783\n",
              "0        1      5      L  1  1  1  4  3  ...    0    1    2    4    4    4    3    4\n",
              "1        2      0      B  0  4  0  0  4  ...    0    1    4    1    4    2    1    2\n",
              "2        3      4      L  1  1  2  2  1  ...    3    0    2    0    3    0    2    2\n",
              "3        4      9      D  1  2  0  2  0  ...    2    0    1    4    0    0    1    1\n",
              "4        5      6      A  3  0  2  4  0  ...    3    2    1    3    4    3    1    2\n",
              "...    ...    ...    ... .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "2043  2044      6      V  2  4  3  4  2  ...    2    0    0    1    3    1    4    0\n",
              "2044  2045      1      L  3  2  2  1  1  ...    4    2    1    2    3    4    1    1\n",
              "2045  2046      9      A  4  0  4  0  2  ...    1    1    3    4    2    2    0    0\n",
              "2046  2047      0      Z  2  3  3  0  3  ...    1    1    0    4    1    4    3    1\n",
              "2047  2048      5      Z  4  2  2  1  3  ...    4    0    4    3    2    4    3    4\n",
              "\n",
              "[2048 rows x 787 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NzDrTLwRajfQ"
      },
      "source": [
        "X_train = (train[[str(i) for i in range(784)]] / 255.).values.reshape(-1,28,28,1) # namalization 0~1의 값\n",
        "y_train = to_categorical(train['digit'].values) # one-hot encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFbYigMyXiWk",
        "outputId": "9c8c937b-afaa-405a-d47b-eab518f9f5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QXViFC7FajfX"
      },
      "source": [
        "X_letter = train.iloc[:,2].values # 알파벳 아스키코드로 변환\n",
        "for idx in range(len(X_letter)):\n",
        "    X_letter[idx] = ord(X_letter[idx]) #ord() 안에 문자값을 넣어 주면 아스키코드로 변환 ex) Z = 90\n",
        "X_letterToNum = X_letter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oq0Ctbw1ajfh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8KmST2JYajfm"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,Conv1D, BatchNormalization, Dropout, MaxPool2D, Activation,\n",
        "    Flatten, Dense, Input, Concatenate, LeakyReLU, Add, AveragePooling2D,GlobalAveragePooling2D\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "import argparse\n",
        "import locale\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ukkhCW8wajfv"
      },
      "source": [
        "dim = 7 # 이진화 한 수가 들어갈 차원 정의"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IBlxrsVNajf2"
      },
      "source": [
        "inputs1 = Input((7,1))\n",
        "\n",
        "mlp = Dense(16, activation='relu', kernel_initializer='he_normal' ,bias_regularizer=regularizers.l2(l=0.1))(inputs1)\n",
        "mlp = Dense(8, activation='relu', kernel_initializer='he_normal',bias_regularizer=regularizers.l2(l=0.1))(mlp)\n",
        "mlp = Dense(4, activation='relu', kernel_initializer='he_normal',bias_regularizer=regularizers.l2(l=0.1))(mlp)\n",
        "mlp = Flatten()(mlp)\n",
        "\n",
        "mlp = Model(inputs1, mlp) # chain layer call"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o9qaadccajf9"
      },
      "source": [
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sSPOwBTIajgC"
      },
      "source": [
        " # Remove the previous model.(resnet모델을 본따서 만든 것)\n",
        "model = None\n",
        "    \n",
        "# Input layer\n",
        "img_input = layers.Input(shape = (28,28,1)) # 이미지 형태\n",
        "\n",
        "# CNN\n",
        "# Identity mapping shortcut을 위한 conv_1 layer\n",
        "conv_1 = layers.Conv2D(128, kernel_size = 3, padding = 'same', kernel_initializer='he_normal',activation = 'relu')(img_input) # 입력 이미지와 출력 이미지 같게 padding = same\n",
        "\n",
        "conv_2_1 = layers.Conv2D(128, kernel_size = 3, padding = 'same', kernel_initializer='he_normal',activation = 'relu')(conv_1)\n",
        "conv_2_1 = layers.Conv2D(128, kernel_size = 3, padding = 'same', kernel_initializer='he_normal')(conv_2_1)\n",
        "\n",
        "\n",
        "# ShortCut connection\n",
        "add_2_1 = layers.add([conv_1, conv_2_1])\n",
        "add_2_1 = BatchNormalization()(add_2_1)\n",
        "out_2_1 = layers.Activation('relu')(add_2_1)\n",
        "\n",
        "conv_2_2 = layers.Conv2D(128, kernel_size = 3, padding = 'same',kernel_initializer='he_normal', activation = 'relu')(out_2_1) # 다시 층 쌓기\n",
        "conv_2_2 = layers.Conv2D(128, kernel_size = 3, padding = 'same',kernel_initializer='he_normal')(conv_2_2)\n",
        "\n",
        "# ShortCut connection\n",
        "add_2_2 = layers.add([out_2_1, conv_2_2])\n",
        "add_2_2= BatchNormalization()(add_2_2) # batchnomalization\n",
        "out_2_2 = layers.Activation('relu')(add_2_1)\n",
        "\n",
        "pool_2 = layers.MaxPool2D((2,2), strides = 2)(out_2_2) \n",
        "\n",
        "conv_3_0 = layers.Conv2D(256, kernel_size = 1, strides = 1, kernel_initializer='he_normal')(pool_2)\n",
        "\n",
        "conv_3_1 = layers.Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu',kernel_initializer='he_normal')(conv_3_0)\n",
        "conv_3_1 = layers.Conv2D(256, kernel_size = 3, padding = 'same',kernel_initializer='he_normal')(conv_3_1)\n",
        "\n",
        "# ShortCut connection\n",
        "add_3_1 = layers.add([conv_3_0, conv_3_1])\n",
        "add_3_1= BatchNormalization()(add_3_1)\n",
        "\n",
        "out_3_1 = layers.Activation('relu')(add_3_1)\n",
        "\n",
        "conv_3_2 = layers.Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu',kernel_initializer='he_normal')(out_3_1)\n",
        "conv_3_2 = layers.Conv2D(256, kernel_size = 3, padding = 'same',kernel_initializer='he_normal')(conv_3_2)\n",
        "\n",
        "# ShortCut connection\n",
        "add_3_2 = layers.add([out_3_1, conv_3_2])\n",
        "add_3_2= BatchNormalization()(add_3_2)\n",
        "\n",
        "out_3_2 = layers.Activation('relu')(add_3_2)\n",
        "\n",
        "pool_3 = layers.MaxPool2D((2,2), strides = 2)(out_3_2)\n",
        "\n",
        "conv_4_0 = layers.Conv2D(256, kernel_size = 1, strides = 1)(pool_3)\n",
        "\n",
        "conv_4_1 = layers.Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu',kernel_initializer='he_normal')(conv_4_0)\n",
        "conv_4_1 = layers.Conv2D(256, kernel_size = 3, padding = 'same',kernel_initializer='he_normal')(conv_4_1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ShortCut connection\n",
        "add_4_1 = layers.add([conv_4_0, conv_4_1])\n",
        "add_4_1= BatchNormalization()(add_4_1)\n",
        "\n",
        "out_4_1 = layers.Activation('relu')(add_4_1)\n",
        "\n",
        "pool_4 = layers.MaxPool2D((2,2), strides = 2)(out_4_1)\n",
        "\n",
        "conv_5_0 = layers.Conv2D(256, kernel_size = 1, strides = 1)(pool_4)\n",
        "\n",
        "conv_4_2 = layers.Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu',kernel_initializer='he_normal')(conv_5_0)\n",
        "conv_4_2 = layers.Conv2D(256, kernel_size = 3, padding = 'same',kernel_initializer='he_normal')(conv_4_1)\n",
        "\n",
        "# ShortCut connection\n",
        "add_4_2 = layers.add([out_4_1, conv_4_2])\n",
        "add_4_2= BatchNormalization()(add_4_2)\n",
        "\n",
        "out_4_2 = layers.Activation('relu')(add_4_2)\n",
        "\n",
        "pool_5 = layers.MaxPool2D((2,2), strides = 2)(out_4_2)\n",
        "\n",
        "conv_5_0 = layers.Conv2D(256, kernel_size = 1, strides = 1)(pool_4)\n",
        "\n",
        "conv_5_1 = layers.Conv2D(256, kernel_size = 3, padding = 'same', activation = 'relu',kernel_initializer='he_normal')(conv_5_0)\n",
        "conv_5_1 = layers.Conv2D(256, kernel_size = 3, padding = 'same',kernel_initializer='he_normal')(conv_5_1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ShortCut connection\n",
        "add_5_1 = layers.add([conv_5_0, conv_5_1])\n",
        "add_5_1= BatchNormalization()(add_5_1)\n",
        "\n",
        "out_5_1 = layers.Activation('relu')(add_5_1)\n",
        "\n",
        "pool_5 = layers.MaxPool2D((2,2), strides = 2)(out_5_1)\n",
        "\n",
        "\n",
        "# FC layers\n",
        "img_features = layers.Flatten()(pool_5)\n",
        "img_features = layers.Dense(512, activation = 'relu',kernel_regularizer=regularizers.l2(l=0.1))(img_features)\n",
        "img_features = layers.Dropout(rate = 0.4)(img_features)\n",
        "img_features = layers.Dense(512, activation = 'relu',kernel_regularizer=regularizers.l2(l=0.1))(img_features)   \n",
        "img_features = layers.Dropout(rate = 0.4)(img_features)\n",
        "    \n",
        "x = Model(img_input, img_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oOFJtM4najgG"
      },
      "source": [
        "combinedInput = concatenate([mlp.output, x.output]) # 합치기(새로운 input) 알파벳 예측, 숫자예측"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DEQ94SEuajgN"
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TiiwWgqjajgS"
      },
      "source": [
        "y = Dense(10, activation=\"softmax\")(combinedInput)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "K8I5aoTGajgY"
      },
      "source": [
        "final_model = Model(inputs=[mlp.input, x.input], outputs=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9A5UCmbFajgg"
      },
      "source": [
        "final_model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GmAosCi_ajgn"
      },
      "source": [
        "X_letterToNum = np.asarray(X_letterToNum).astype(np.float32) # 이미지 처리를 위해 float32로 변경.\n",
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kZPEmcwuajgs"
      },
      "source": [
        "datagen = ImageDataGenerator(width_shift_range=5, # 예를 들어 전체 넓이가 100이라면 20픽셀 내외로 움직임\n",
        "                                 height_shift_range=5, #수직방향으로 20픽셀 내외\n",
        "                                 rotation_range=90, #0~90도 사이 임의로\n",
        "                                 zoom_range=0.05) #  “1-수치”부터 “1+수치”0.95~1.05사이의 확대.\n",
        "\n",
        "#두번의 이미지 증강\n",
        "flow1 = datagen.flow(X_train, X_letterToNum, batch_size=32, seed=1218) # 이미지와 알파벳에 따른 이미지 증강\n",
        "flow2 = datagen.flow(X_train, y_train, batch_size=32, seed=1218) # 이미지와 숨어있는 숫자 값에 따른 이미지 증강"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6yC4wO8bajgw"
      },
      "source": [
        "i = 0\n",
        "while i < 1500:\n",
        "    X_image_gen1,X_letter_gen=flow1.next()\n",
        "    X_image_gen2,y_gen=flow2.next()\n",
        "\n",
        "    X_image_gen1 = np.asarray(X_image_gen1).astype(np.float32)\n",
        "    X_letter_gen = np.asarray(X_letter_gen).astype(np.float32)\n",
        "    y_gen = np.asarray(y_gen).astype(np.float32)\n",
        "    \n",
        "    X_train = np.r_[X_train, X_image_gen1] # 데이터를 옆으로 붙이기\n",
        "    X_letterToNum = np.r_[X_letterToNum, X_letter_gen] # 같다\n",
        "    y_train = np.r_[y_train,y_gen] # 같다\n",
        "    \n",
        "    i += 1\n",
        "    '''\n",
        "    print(\"X_train.shape={}\".format(X_train.shape))\n",
        "    print(\"X_letterToNum.shape={}\".format(X_letterToNum.shape))\n",
        "    print(\"y_train.shape={}\".format(y_train.shape))\n",
        "    print('\\n')\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O2ozs8Yajg2"
      },
      "source": [
        "## letter data 를 이진화 해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XzzHcTb9ajg3"
      },
      "source": [
        "X_letterToNum = X_letterToNum.astype(np.int) # 정수형으로 변환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KFI7fShvajg9",
        "outputId": "64f4e693-06ca-4a6f-d41a-430c7c6cacb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.zeros(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EMCi-jnfajhE"
      },
      "source": [
        "X_letterToBi = []\n",
        "for i in range(len(X_letterToNum)):\n",
        "    tmp = X_letterToNum[i]\n",
        "    bi = np.zeros(7)\n",
        "    k = 6\n",
        "    while tmp > 0 and k >= 0:\n",
        "        if tmp >= pow(2, k):\n",
        "            bi[6-k] = 1\n",
        "            tmp -= pow(2, k)\n",
        "        k -= 1\n",
        "    X_letterToBi.append(bi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSfNUyGBrB1j",
        "outputId": "5ee2d570-85af-4f59-f382-423273628d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "X_letterToBi[0:5] # 마지막 알파벳인 Z의 아스키코드 90.이것을 이진화 하고싶다. [7개의 숫자] 2의 7제곱의 경우의 수 = 128 / 표현 가능. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1., 0., 0., 1., 1., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 1., 0.]),\n",
              " array([1., 0., 0., 1., 1., 0., 0.]),\n",
              " array([1., 0., 0., 0., 1., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 1.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "foNh8GkpajhI"
      },
      "source": [
        "X_letterToBi = np.asarray(X_letterToBi).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q1_cHoUUajhO",
        "outputId": "71b76e97-fe6a-4f95-bcbf-19984ee254d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98048, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qKow-DyFajhS",
        "outputId": "e2bdafd0-238d-433e-aa74-91b3a5fdc699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_letterToBi.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98048, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qv15HSvOajhX"
      },
      "source": [
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ILpA44J5ajhd"
      },
      "source": [
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ke9Wf-ddajhk",
        "outputId": "5dc6da69-cb43-4cfe-8dc2-338621b7e953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        }
      },
      "source": [
        "history = final_model.fit(\n",
        "    x=[X_letterToBi, X_train], y=y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=epochs, \n",
        "    callbacks=[annealer],\n",
        "    steps_per_epoch=X_train\n",
        "    .shape[0]//32,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3064/3064 [==============================] - 42s 14ms/step - loss: 1.6097 - accuracy: 0.4780 - val_loss: 1.8894 - val_accuracy: 0.3933\n",
            "Epoch 2/20\n",
            "3064/3064 [==============================] - 42s 14ms/step - loss: 1.4878 - accuracy: 0.5276 - val_loss: 1.7203 - val_accuracy: 0.4498\n",
            "Epoch 3/20\n",
            "3064/3064 [==============================] - 41s 14ms/step - loss: 1.3505 - accuracy: 0.5901 - val_loss: 1.7272 - val_accuracy: 0.4592\n",
            "Epoch 4/20\n",
            "3064/3064 [==============================] - 41s 13ms/step - loss: 1.2240 - accuracy: 0.6410 - val_loss: 1.5955 - val_accuracy: 0.5116\n",
            "Epoch 5/20\n",
            "3064/3064 [==============================] - 41s 13ms/step - loss: 1.1116 - accuracy: 0.6818 - val_loss: 1.5571 - val_accuracy: 0.5357\n",
            "Epoch 6/20\n",
            "3064/3064 [==============================] - 41s 13ms/step - loss: 1.0092 - accuracy: 0.7150 - val_loss: 1.5630 - val_accuracy: 0.5406\n",
            "Epoch 7/20\n",
            "3064/3064 [==============================] - 41s 13ms/step - loss: 0.9220 - accuracy: 0.7440 - val_loss: 1.6115 - val_accuracy: 0.5446\n",
            "Epoch 8/20\n",
            "3064/3064 [==============================] - 42s 14ms/step - loss: 0.8289 - accuracy: 0.7750 - val_loss: 1.6128 - val_accuracy: 0.5554\n",
            "Epoch 9/20\n",
            "3064/3064 [==============================] - 41s 13ms/step - loss: 0.7551 - accuracy: 0.7989 - val_loss: 1.5910 - val_accuracy: 0.5515\n",
            "Epoch 10/20\n",
            "3064/3064 [==============================] - 41s 13ms/step - loss: 0.6837 - accuracy: 0.8209 - val_loss: 1.6807 - val_accuracy: 0.5725\n",
            "Epoch 11/20\n",
            " 614/3064 [=====>........................] - ETA: 31s - loss: 0.6094 - accuracy: 0.8468"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-40f3a210989b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J-nKSF-gajhp",
        "outputId": "5e3996a1-c2c9-408a-dec8-9cc8e782824d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.figure()\n",
        "\n",
        "epoch = np.arange(epochs)\n",
        "\n",
        "plt.plot(epoch, np.asarray(history.history['accuracy']),label=\"acc\")\n",
        "plt.plot(epoch, np.asarray(history.history['val_accuracy']),label=\"val_acc\")\n",
        "\n",
        "plt.title('Accuracy vs val_accuracy')\n",
        "plt.ylim(0,1)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.02,1),loc=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc786772a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M3fSPdyyajhs"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KtqY4oLPajhx"
      },
      "source": [
        "test.iloc[:,1].values[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9ZBhFkaXajh3"
      },
      "source": [
        "X_test_letter = test.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8Q0UNNHWajh9"
      },
      "source": [
        "for idx in range(len(X_test_letter)):\n",
        "    X_test_letter[idx] = ord(X_test_letter[idx])\n",
        "X_letterToNum_test = X_test_letter.astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_FFpEs3bajiC"
      },
      "source": [
        "X_letterToBi_test = []\n",
        "for i in range(len(X_letterToNum_test)):\n",
        "    tmp = X_letterToNum_test[i]\n",
        "    bi = np.zeros(7)\n",
        "    k = 6\n",
        "    while tmp > 0 and k >= 0:\n",
        "        if tmp >= pow(2, k):\n",
        "            bi[6-k] = 1\n",
        "            tmp -= pow(2, k)\n",
        "        k -= 1\n",
        "    X_letterToBi_test.append(bi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vMhRl93tajiG"
      },
      "source": [
        "X_letterToBi_test = np.asarray(X_letterToBi_test).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_yJgCVajiK"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q_VQoBx8ajiL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "17UpUiTNajiP"
      },
      "source": [
        "train_df = pd.read_csv('./My Drive/train.csv', usecols = lambda column : column not in [\"id\" , \"letter\"])\n",
        "test_df = pd.read_csv('./My Drive/test.csv',usecols = lambda column : column not in [\"id\" , \"letter\"])\n",
        "submission = pd.read_csv('./My Drive/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Carn1j9sajiS",
        "outputId": "cdf18aed-b944-44c5-b6f5-b9b63bd2946d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "# have a glimpse of train dataframe structure\n",
        "n_train = len(train_df)\n",
        "n_pixels = len(train_df.columns) - 1\n",
        "n_class = len(set(train_df['digit']))\n",
        "print('Number of training samples: {0}'.format(n_train))\n",
        "print('Number of training pixels: {0}'.format(n_pixels))\n",
        "print('Number of classes: {0}'.format(n_class))\n",
        "print(train_df.head())\n",
        "\n",
        "# have a glimpse of test dataframe structure\n",
        "n_test = len(test_df)\n",
        "n_pixels = len(test_df.columns)\n",
        "print('Number of test samples: {0}'.format(n_test))\n",
        "print('Number of test pixels: {0}'.format(n_pixels))\n",
        "print(test_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 2048\n",
            "Number of training pixels: 784\n",
            "Number of classes: 10\n",
            "   digit  0  1  2  3  4  5  6  7  ...  775  776  777  778  779  780  781  782  783\n",
            "0      5  1  1  1  4  3  0  0  4  ...    1    0    1    2    4    4    4    3    4\n",
            "1      0  0  4  0  0  4  1  1  1  ...    3    0    1    4    1    4    2    1    2\n",
            "2      4  1  1  2  2  1  1  1  0  ...    3    3    0    2    0    3    0    2    2\n",
            "3      9  1  2  0  2  0  4  0  3  ...    3    2    0    1    4    0    0    1    1\n",
            "4      6  3  0  2  4  0  3  0  4  ...    4    3    2    1    3    4    3    1    2\n",
            "\n",
            "[5 rows x 785 columns]\n",
            "Number of test samples: 20480\n",
            "Number of test pixels: 784\n",
            "   0  1  2  3  4  5  6  7  8  ...  775  776  777  778  779  780  781  782  783\n",
            "0  0  4  0  2  4  2  3  1  0  ...    0    4    2    2    4    3    4    1    4\n",
            "1  4  1  4  0  1  1  0  2  2  ...    3    2    4    2    4    2    2    1    2\n",
            "2  0  4  0  1  3  2  3  0  2  ...    3    2    0    3    2    3    0    1    4\n",
            "3  2  1  3  3  3  4  3  0  0  ...    0    3    2    4    1    0    4    4    4\n",
            "4  1  0  1  1  2  2  1  4  1  ...    3    1    4    0    2    1    2    3    4\n",
            "\n",
            "[5 rows x 784 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ppGsyjYCajiW",
        "outputId": "510062c6-1fdb-4ff2-98ee-80d6ba170927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "random_sel = np.random.randint(n_train, size=8)\n",
        "\n",
        "grid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].values/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\n",
        "plt.rcParams['figure.figsize'] = (16, 2)\n",
        "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
        "plt.axis('off')\n",
        "print(*list(train_df.iloc[random_sel, 0].values), sep = ', ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1, 5, 2, 4, 1, 4, 7, 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MPvoW5Bpajia"
      },
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    \"\"\"MNIST dtaa set\"\"\"\n",
        "    \n",
        "    def __init__(self, dataframe, \n",
        "                 transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "                ):\n",
        "        df = dataframe\n",
        "        # for MNIST dataset n_pixels should be 784\n",
        "        self.n_pixels = 784\n",
        "        \n",
        "        if len(df.columns) == self.n_pixels:\n",
        "            # test data\n",
        "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
        "            self.y = None\n",
        "        else:\n",
        "            # training data\n",
        "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
        "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
        "            \n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is not None:\n",
        "            return self.transform(self.X[idx]), self.y[idx]\n",
        "        else:\n",
        "            return self.transform(self.X[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xxnyza5pajie"
      },
      "source": [
        "RandAffine = transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VcJ9yRoCajil",
        "outputId": "8917146e-0cb4-42eb-91b6-769e64799570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rotate = transforms.RandomRotation(degrees=0)\n",
        "shift = RandAffine\n",
        "composed = transforms.Compose([rotate,\n",
        "                               shift])\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "fig = plt.figure()\n",
        "sample = transforms.ToPILImage()(train_df.iloc[65,1:].values.reshape((28,28)).astype(np.uint8)[:,:,None])\n",
        "for i, tsfrm in enumerate([rotate, shift, composed]):\n",
        "    transformed_sample = tsfrm(sample)\n",
        "\n",
        "    ax = plt.subplot(1, 3, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(type(tsfrm).__name__)\n",
        "    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,28)), cmap='gray')    \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W9T_wRIDajis"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_transforms = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     RandAffine,\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "\n",
        "val_test_transforms = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
        "\n",
        "def get_dataset(dataframe, dataset=MNISTDataset,\n",
        "                transform=transforms.Compose([transforms.ToPILImage(),\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n",
        "    return dataset(dataframe, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rq7125vAajiz"
      },
      "source": [
        "resnet18 = models.resnet18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "APhJyfT2aji3",
        "outputId": "3482ab3a-a62e-4a8b-8459-84cd5526f44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
        "\n",
        "class MNISTResNet(ResNet):\n",
        "    def __init__(self):\n",
        "        super(MNISTResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10) # Based on ResNet18\n",
        "        #super(MNISTResNet, self).__init__(BasicBlock, [3, 4, 6, 3], num_classes=10) # Based on ResNet34\n",
        "        #super(MNISTResNet, self).__init__(Bottleneck, [3, 4, 6, 3], num_classes=10) # Based on ResNet50\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=3,bias=False)\n",
        "\n",
        "model = MNISTResNet()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNISTResNet(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bjeRdu8Gaji9"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader): \n",
        "        # if GPU available, move data and target to GPU\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        # compute output and loss\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # TODO:\n",
        "        # 1. add batch metric (acc1, acc5)\n",
        "        # 2. add average metric top1=sum(acc1)/batch_idx, top5 = sum(acc5)/batch_idx\n",
        "        \n",
        "        # backward and update model\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    print('Train Epoch: {} , Accuracy: {}/{} ({:.3f}%)'.format(\n",
        "        epoch ,correct, len(train_loader.dataset),100.0 * float(correct) / len(train_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1WvImrvRajjE"
      },
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for _, (data, target) in enumerate(val_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        output = model(data)\n",
        "        \n",
        "        loss += criterion(output, target).data.item()\n",
        "\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    loss /= len(val_loader.dataset)\n",
        "        \n",
        "    print('On Val set Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)'.format(\n",
        "        loss, correct, len(val_loader.dataset),\n",
        "        100.0 * float(correct) / len(val_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zhE9VlncajjJ",
        "outputId": "d87be735-d413-4298-94ae-bd680c2024d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "total_epoches = 1\n",
        "step_size = 1\n",
        "base_lr = 1\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "def split_dataframe(dataframe=None, fraction=0.9, rand_seed=1):\n",
        "    df_1 = dataframe.sample(frac=fraction, random_state=rand_seed)\n",
        "    df_2 = dataframe.drop(df_1.index)\n",
        "    return df_1, df_2\n",
        "for epoch in range(total_epoches):\n",
        "    print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n",
        "\n",
        "    train_df_new, val_df = split_dataframe(dataframe=train_df, fraction=0.9, rand_seed=epoch)\n",
        "    \n",
        "    train_dataset = get_dataset(train_df_new, transform=train_transforms)\n",
        "    val_dataset = get_dataset(val_df, transform=val_test_transforms)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                               batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                             batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Epoch 0: lr = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JCTKx58SajjO",
        "outputId": "7dcd07fb-71c0-47ce-f841-caaf987e17b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "total_epoches = 30\n",
        "step_size = 10\n",
        "base_lr = 0.01\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
        "\n",
        "for epoch in range(total_epoches):\n",
        "    print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n",
        "\n",
        "    train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n",
        "    validate(val_loader=val_loader, model=model, criterion=criterion)\n",
        "    exp_lr_scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Epoch 0: lr = 0.01\n",
            "Train Epoch: 0 , Accuracy: 372/1843 (20.184%)\n",
            "On Val set Average loss: 0.0752, Accuracy: 39/205 (19.024%)\n",
            "\n",
            "Train Epoch 1: lr = 0.01\n",
            "Train Epoch: 1 , Accuracy: 697/1843 (37.819%)\n",
            "On Val set Average loss: 0.0296, Accuracy: 92/205 (44.878%)\n",
            "\n",
            "Train Epoch 2: lr = 0.01\n",
            "Train Epoch: 2 , Accuracy: 909/1843 (49.322%)\n",
            "On Val set Average loss: 0.0376, Accuracy: 95/205 (46.341%)\n",
            "\n",
            "Train Epoch 3: lr = 0.01\n",
            "Train Epoch: 3 , Accuracy: 1037/1843 (56.267%)\n",
            "On Val set Average loss: 0.0224, Accuracy: 124/205 (60.488%)\n",
            "\n",
            "Train Epoch 4: lr = 0.01\n",
            "Train Epoch: 4 , Accuracy: 1206/1843 (65.437%)\n",
            "On Val set Average loss: 0.0236, Accuracy: 128/205 (62.439%)\n",
            "\n",
            "Train Epoch 5: lr = 0.01\n",
            "Train Epoch: 5 , Accuracy: 1303/1843 (70.700%)\n",
            "On Val set Average loss: 0.0363, Accuracy: 122/205 (59.512%)\n",
            "\n",
            "Train Epoch 6: lr = 0.01\n",
            "Train Epoch: 6 , Accuracy: 1386/1843 (75.203%)\n",
            "On Val set Average loss: 0.0185, Accuracy: 149/205 (72.683%)\n",
            "\n",
            "Train Epoch 7: lr = 0.01\n",
            "Train Epoch: 7 , Accuracy: 1409/1843 (76.451%)\n",
            "On Val set Average loss: 0.0207, Accuracy: 144/205 (70.244%)\n",
            "\n",
            "Train Epoch 8: lr = 0.01\n",
            "Train Epoch: 8 , Accuracy: 1425/1843 (77.320%)\n",
            "On Val set Average loss: 0.0134, Accuracy: 161/205 (78.537%)\n",
            "\n",
            "Train Epoch 9: lr = 0.01\n",
            "Train Epoch: 9 , Accuracy: 1489/1843 (80.792%)\n",
            "On Val set Average loss: 0.0237, Accuracy: 137/205 (66.829%)\n",
            "\n",
            "Train Epoch 10: lr = 0.0001\n",
            "Train Epoch: 10 , Accuracy: 1554/1843 (84.319%)\n",
            "On Val set Average loss: 0.0097, Accuracy: 171/205 (83.415%)\n",
            "\n",
            "Train Epoch 11: lr = 0.001\n",
            "Train Epoch: 11 , Accuracy: 1654/1843 (89.745%)\n",
            "On Val set Average loss: 0.0090, Accuracy: 175/205 (85.366%)\n",
            "\n",
            "Train Epoch 12: lr = 0.001\n",
            "Train Epoch: 12 , Accuracy: 1676/1843 (90.939%)\n",
            "On Val set Average loss: 0.0083, Accuracy: 173/205 (84.390%)\n",
            "\n",
            "Train Epoch 13: lr = 0.001\n",
            "Train Epoch: 13 , Accuracy: 1671/1843 (90.667%)\n",
            "On Val set Average loss: 0.0092, Accuracy: 175/205 (85.366%)\n",
            "\n",
            "Train Epoch 14: lr = 0.001\n",
            "Train Epoch: 14 , Accuracy: 1691/1843 (91.753%)\n",
            "On Val set Average loss: 0.0080, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 15: lr = 0.001\n",
            "Train Epoch: 15 , Accuracy: 1688/1843 (91.590%)\n",
            "On Val set Average loss: 0.0093, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 16: lr = 0.001\n",
            "Train Epoch: 16 , Accuracy: 1707/1843 (92.621%)\n",
            "On Val set Average loss: 0.0110, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 17: lr = 0.001\n",
            "Train Epoch: 17 , Accuracy: 1713/1843 (92.946%)\n",
            "On Val set Average loss: 0.0090, Accuracy: 171/205 (83.415%)\n",
            "\n",
            "Train Epoch 18: lr = 0.001\n",
            "Train Epoch: 18 , Accuracy: 1710/1843 (92.784%)\n",
            "On Val set Average loss: 0.0086, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 19: lr = 0.001\n",
            "Train Epoch: 19 , Accuracy: 1733/1843 (94.031%)\n",
            "On Val set Average loss: 0.0126, Accuracy: 168/205 (81.951%)\n",
            "\n",
            "Train Epoch 20: lr = 1e-05\n",
            "Train Epoch: 20 , Accuracy: 1735/1843 (94.140%)\n",
            "On Val set Average loss: 0.0109, Accuracy: 176/205 (85.854%)\n",
            "\n",
            "Train Epoch 21: lr = 0.0001\n",
            "Train Epoch: 21 , Accuracy: 1734/1843 (94.086%)\n",
            "On Val set Average loss: 0.0087, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 22: lr = 0.0001\n",
            "Train Epoch: 22 , Accuracy: 1733/1843 (94.031%)\n",
            "On Val set Average loss: 0.0114, Accuracy: 173/205 (84.390%)\n",
            "\n",
            "Train Epoch 23: lr = 0.0001\n",
            "Train Epoch: 23 , Accuracy: 1739/1843 (94.357%)\n",
            "On Val set Average loss: 0.0130, Accuracy: 173/205 (84.390%)\n",
            "\n",
            "Train Epoch 24: lr = 0.0001\n",
            "Train Epoch: 24 , Accuracy: 1750/1843 (94.954%)\n",
            "On Val set Average loss: 0.0082, Accuracy: 173/205 (84.390%)\n",
            "\n",
            "Train Epoch 25: lr = 0.0001\n",
            "Train Epoch: 25 , Accuracy: 1747/1843 (94.791%)\n",
            "On Val set Average loss: 0.0088, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 26: lr = 0.0001\n",
            "Train Epoch: 26 , Accuracy: 1748/1843 (94.845%)\n",
            "On Val set Average loss: 0.0121, Accuracy: 174/205 (84.878%)\n",
            "\n",
            "Train Epoch 27: lr = 0.0001\n",
            "Train Epoch: 27 , Accuracy: 1734/1843 (94.086%)\n",
            "On Val set Average loss: 0.0089, Accuracy: 175/205 (85.366%)\n",
            "\n",
            "Train Epoch 28: lr = 0.0001\n",
            "Train Epoch: 28 , Accuracy: 1746/1843 (94.737%)\n",
            "On Val set Average loss: 0.0094, Accuracy: 173/205 (84.390%)\n",
            "\n",
            "Train Epoch 29: lr = 0.0001\n",
            "Train Epoch: 29 , Accuracy: 1743/1843 (94.574%)\n",
            "On Val set Average loss: 0.0100, Accuracy: 174/205 (84.878%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BFxuwoH8ajjT"
      },
      "source": [
        "total_epoches = 30\n",
        "step_size = 10\n",
        "base_lr = 0.01\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=base_lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
        "\n",
        "for epoch in range(total_epoches):\n",
        "    print(\"\\nTrain Epoch {}: lr = {}\".format(epoch, exp_lr_scheduler.get_lr()[0]))\n",
        "\n",
        "    train_df_new, val_df = split_dataframe(dataframe=train_df, fraction=0.9, rand_seed=epoch)\n",
        "    \n",
        "    train_dataset = get_dataset(train_df_new, transform=train_transforms)\n",
        "    val_dataset = get_dataset(val_df, transform=val_test_transforms)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                               batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                             batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    train(train_loader=train_loader, model=model, criterion=criterion, optimizer=optimizer, epoch=epoch)\n",
        "    validate(val_loader=val_loader, model=model, criterion=criterion)\n",
        "    exp_lr_scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eUpPOeRKajjX"
      },
      "source": [
        "def prediciton(test_loader, model):\n",
        "    model.eval()\n",
        "    test_pred = torch.LongTensor()\n",
        "    \n",
        "    for i, data in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            \n",
        "        output = model(data)\n",
        "        \n",
        "        pred = output.cpu().data\n",
        "        if i == 0 :\n",
        "            test_pred = pred\n",
        "        else :\n",
        "            test_pred = torch.cat([test_pred,pred], dim=0)\n",
        "        \"\"\"\n",
        "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
        "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
        "        \"\"\"\n",
        "        del pred\n",
        "        \n",
        "    return test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qhAS-NnHajjb"
      },
      "source": [
        "test_batch_size = 64\n",
        "test_dataset = get_dataset(test_df, transform=val_test_transforms)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "# tensor prediction\n",
        "pred_output = prediciton(test_loader, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7Nc0_awrajjh"
      },
      "source": [
        "X_test = (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1,28,28,1)\n",
        "\n",
        "pred_output_keras = final_model.predict([X_letterToBi_test,X_test])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qGGyzmwLajjp",
        "outputId": "02601b07-3653-4103-9135-6305bad6c7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pred_output[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0031, -0.9606,  1.6719,  0.2488,  0.5495,  0.3143,  4.8859, -2.0453,\n",
              "         6.3600, -1.4474])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BKH8Zzb5ajju"
      },
      "source": [
        "pred_output_keras[7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mBh2tWyeajj0"
      },
      "source": [
        "((pred_output + pred_output_keras) / 2)[7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XvCLKmfDajj8"
      },
      "source": [
        "results = np.argmax((pred_output + pred_output_keras) / 2,axis=1) # 가장 큰 값 반환."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-6kV1hYmajkC"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GcO5zlM3ajkL"
      },
      "source": [
        "submission.digit = results\n",
        "submission.to_csv('submission_09-14_앙상블_마지막.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Oar1B71KajkR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qkct7ZLTajkY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9y91gQ7_ajke"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}